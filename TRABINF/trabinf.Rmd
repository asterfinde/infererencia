---
title: ""
author: ""
date: ""
output: 
  html_document:
    toc: true
    toc_float: true
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE, 
  warning = FALSE)
```

::: {style="text-align:center; margin-top:80px; font-family: Arial, sans-serif;"}
### UNIVERSIDAD NACIONAL AGRARIA

### 

LA MOLINA

<br>

### FACULTAD DE ECONOM√çA Y PLANIFICACI√ñN

### ESTAD√çSTICA E INFORM√ÅTICA

<br>

<img src="logo_unalm.png" width="180" style="margin:20px;"/>

<br>

**TRABAJO FINAL INTEGRADOR**

<br><br>

**Presentado por:**

FR√çAS GOMEZ, LEONARDO JOAQUIN 

SAAVEDRA ACU√ëA, KAMILA NICOLL

CORONADO DE LA VEGA, HECTOR ALONSO

BRYAN VARGAS

<br><br>

**INFERENCIA ESTAD√çSTICA**

<br><br><br><br>

**LIMA ‚Äì PER√ö**\
**A√ëO 2025**
:::

::: {style="page-break-after: always;"}
:::

```{r librerias, echo=FALSE, results="hide"}
library(readxl)
library(dplyr)
library(ggplot2)
library(knitr)
library(kableExtra)
```

# **1. Introducci√≥n**

## **1.1 Contexto del estudio**

El Ministerio de Salud ha implementado un nuevo programa de seguimiento dirigido a pacientes con enfermedades cr√≥nicas que presentan episodios recurrentes de crisis de salud. Este programa tiene como finalidad mejorar el control cl√≠nico de los pacientes, reducir la frecuencia de visitas a los servicios de emergencia y favorecer una recuperaci√≥n m√°s r√°pida luego de cada episodio cr√≠tico.

En el marco de esta intervenci√≥n, se ha recolectado informaci√≥n correspondiente a 200 pacientes durante un periodo de seis meses, registr√°ndose variables vinculadas a la frecuencia de atenci√≥n m√©dica de emergencia, el estado de salud de los pacientes al inicio y al final del periodo de seguimiento, y el tiempo requerido para su recuperaci√≥n posterior a una crisis. Estas variables permiten analizar tanto el comportamiento de eventos discretos asociados a las visitas de emergencia como los cambios en la condici√≥n cl√≠nica de los pacientes a partir de observaciones pareadas, as√≠ como la evoluci√≥n del tiempo de recuperaci√≥n, el cual corresponde a una variable continua que no necesariamente sigue una distribuci√≥n normal.

Desde el punto de vista del an√°lisis estad√≠stico, el objetivo es aplicar t√©cnicas de inferencia estad√≠stica que permitan entender el comportamiento de los datos, estimar par√°metros relevantes y contrastar hip√≥tesis relacionadas con el impacto del programa de seguimiento. A trav√©s de este an√°lisis se busca aportar evidencia que ayude a evaluar la efectividad de la intervenci√≥n implementada y que sirva como apoyo para la toma de decisiones en el √°mbito de la salud p√∫blica.

## **1.2. Justificaci√≥n**

El presente trabajo se justifica por la necesidad de aplicar de forma pr√°ctica los principales conceptos de la inferencia estad√≠stica utilizando una base de datos realista vinculada al √°mbito de la salud. El an√°lisis de informaci√≥n de pacientes con enfermedades cr√≥nicas permite trabajar con diferentes tipos de variables y aplicar t√©cnicas de estimaci√≥n, pruebas de hip√≥tesis y evaluaci√≥n de modelos probabil√≠sticos.

En particular, el estudio del n√∫mero de visitas a emergencia y del tiempo de recuperaci√≥n permite analizar el ajuste de los datos a distintas distribuciones te√≥ricas y evaluar su comportamiento estad√≠stico. Asimismo, la informaci√≥n sobre el estado de salud de los pacientes antes y despu√©s del seguimiento hace posible aplicar pruebas de hip√≥tesis para datos pareados, lo que resulta √∫til para evaluar cambios asociados al programa implementado.

De esta manera, el desarrollo del trabajo contribuye a reforzar la interpretaci√≥n de resultados estad√≠sticos y el uso de t√©cnicas estad√≠sticas como apoyo para la toma de decisiones basadas en evidencia, tanto desde un punto de vista acad√©mico como aplicado.

## **1.3. Objetivos del trabajo**

**Objetivo General**

Aplicar t√©cnicas de inferencia estad√≠stica a una base de datos de pacientes con enfermedades cr√≥nicas, con el fin de analizar el comportamiento de las visitas a emergencia, los cambios en el estado de salud y el tiempo de recuperaci√≥n, evaluando la adecuaci√≥n de distintos modelos probabil√≠sticos y pruebas estad√≠sticas.

**Objetivos Espec√≠ficos**

**a. An√°lisis de estimadores y sus propiedades**

Aplicar al menos cinco estimadores diferentes para los par√°metros asociados a las variables de inter√©s del estudio.

Evaluar las principales propiedades estad√≠sticas de los estimadores utilizados, tales como insesgamiento, consistencia y eficiencia.

**b. Construcci√≥n de intervalos de confianza**

Calcular intervalos de confianza para los par√°metros estimados a partir de las variables seleccionadas.

Analizar la precisi√≥n y el nivel de incertidumbre de los intervalos construidos.

**c. Prueba de hip√≥tesis para proporciones pareadas**

Formular y aplicar una prueba de hip√≥tesis para evaluar cambios en el estado de salud de los pacientes antes y despu√©s del periodo de seguimiento.

Verificar que se cumplan las condiciones necesarias para el uso de pruebas con datos pareados.

**d. Pruebas de hip√≥tesis basadas en estimadores**

Realizar pruebas de hip√≥tesis utilizando los estimadores obtenidos previamente.

Contrastar hip√≥tesis relevantes relacionadas con el comportamiento de las variables analizadas.

**e. An√°lisis de la funci√≥n potencia**

Analizar la funci√≥n potencia de una prueba estad√≠stica considerando poblaciones que no sigan distribuciones normales ni binomiales.

Evaluar la capacidad de la prueba para detectar diferencias significativas bajo distintos escenarios.

**f. Distribuci√≥n asint√≥tica de la raz√≥n de verosimilitud**

Aplicar pruebas basadas en la raz√≥n de verosimilitud para contrastar hip√≥tesis sobre los par√°metros del modelo.

Analizar el comportamiento asint√≥tico de los estimadores de m√°xima verosimilitud en el contexto del estudio.

## **1.4. Metodolog√≠a**

El trabajo se desarroll√≥ en tres fases principales:

**Fase 1: Construcci√≥n y selecci√≥n de la base de datos**
En esta fase se trabaj√≥ con una base de datos simulada que representa informaci√≥n de 200 pacientes con enfermedades cr√≥nicas, recolectada durante un periodo de seguimiento de seis meses. La base incluye variables relacionadas con el n√∫mero de visitas a emergencia, el estado de salud de los pacientes antes y despu√©s del seguimiento y el tiempo de recuperaci√≥n posterior a una crisis.

Tambi√©n, se realiz√≥ la selecci√≥n de las variables principales del estudio, las cuales fueron definidas de acuerdo con su adecuaci√≥n para el desarrollo de los an√°lisis. Estas variables permiten trabajar con datos discretos, continuos y binarios, facilitando la aplicaci√≥n de diferentes m√©todos de inferencia estad√≠stica.

**Fase 2: Implementaci√≥n en R**

En esta fase se llev√≥ a cabo la implementaci√≥n de los procedimientos estad√≠sticos utilizando el software R, desarrollando scripts reproducibles para cada uno de los puntos del trabajo. Se aplicaron t√©cnicas de estimaci√≥n, pruebas de bondad de ajuste, construcci√≥n de intervalos de confianza, pruebas de hip√≥tesis para datos pareados, an√°lisis de la funci√≥n potencia y pruebas basadas en la raz√≥n de verosimilitud.

**Fase 3: An√°lisis e interpretaci√≥n de resultados**

Finalmente, se realiz√≥ el an√°lisis e interpretaci√≥n de los resultados estad√≠sticos obtenidos, relacion√°ndolos con el contexto del estudio. Esta fase incluy√≥ la evaluaci√≥n de los hallazgos principales y la discusi√≥n de los resultados en funci√≥n de los objetivos planteados.

A partir de los resultados obtenidos, se formularon conclusiones basadas en evidencia estad√≠stica, las cuales pueden servir como apoyo para el dise√±o de futuros estudios en el √°mbito de la salud.

# **2. Base de Datos**

## **2.1. Descripci√≥n de Variables**

```{r, echo=FALSE, fig.align='center'}
library(knitr)
library(kableExtra)

variables_estudio <- data.frame(
  Variable = c(
    "Eventos de emergencia (eventos_poisson)",
    "Condici√≥n inicial del paciente",
    "Condici√≥n final del paciente",
    "Tiempo de recuperaci√≥n"
  ),
  Tipo = c(
    "Cuantitativa Discreta",
    "Binaria",
    "Binaria",
    "Cuantitativa Continua"
  ),
  `Valores y/o Rango` = c(
    "0, 1, 2, ... (conteo de visitas a emergencia)",
    "0 = Estable, 1 = Cr√≠tico",
    "0 = Estable, 1 = Cr√≠tico",
    "D√≠as (valores positivos)"
  )
)

kable(
  variables_estudio,
  format = "html",
  caption = "Descripci√≥n de las Variables del Estudio",
  col.names = c("Variable", "Tipo", "Valores y/o Rango")
) %>%
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("striped", "hover", "condensed")
  )
```

## **2.2 Datos**
```{r, echo=FALSE, fig.align='center'}
library(readxl)
library(knitr)
library(kableExtra)

# Cargar la base de datos con las variables principales
datos <- read_excel("Datos_Principales_Inferencia.xlsx")

# Mostrar solo las primeras 10 observaciones
kable(
  head(datos, 10),
  format = "html",
  caption = "Primeras observaciones de la base de datos"
) %>%
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("striped", "hover", "condensed")
  )
```


# **3. An√°lisis Estad√≠stico**

## **3.1 Pruebas de bondad de ajuste**

```{r, echo=FALSE, results="hide"}

# Cargar datos
datos <- read_excel("Datos_Principales_Inferencia.xlsx")

# Resumen de estructura y valores faltantes
resumen <- data.frame(
  Variable = names(datos),
  Tipo = sapply(datos, class),
  NA_count = sapply(datos, function(x) sum(is.na(x)))
)

# Tabla
kable(
  resumen,
  format = "html",
  caption = "Estructura y valores faltantes"
) %>%
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("striped", "hover", "condensed")
  )
```


Antes de ajustar distribuciones, verificamos el tipo de dato y la presencia de valores faltantes. Esto evita problemas en los contrastes y asegura que la inferencia se haga sobre la misma informaci√≥n.

---

### **3.1.1 Bondad de ajuste para eventos_poisson (discreta)**

**Exploraci√≥n b√°sica (media vs varianza, histograma discreto)**

> **Teor√≠a importante (Poisson):** si \(X \sim \text{Poisson}(\lambda)\), entonces  
\[
E(X)=\lambda \quad \text{y} \quad Var(X)=\lambda
\]

Por eso, comparar la media y varianza muestral ayuda a detectar **equidispersi√≥n**. En el contexto de variables de conteo, como eventos_poisson, una propiedad clave de la distribuci√≥n Poisson es la equidispersi√≥n, es decir, que el valor esperado y la varianza poblacional coinciden.

Esta propiedad se eval√∫a de manera exploratoria comparando la media muestral con la varianza muestral. Si ambas son similares, existe evidencia a favor de equidispersi√≥n; si la varianza es mucho mayor que la media, se sospecha sobredispersi√≥n, y si es menor, subdispersi√≥n. Pero es importante decir que esta comparaci√≥n no constituye una prueba formal, pero es un diagn√≥stico inicial.

En los datos analizados se obtuvo el siguiente resumen:

- Tama√±o muestral: \( n = 200 \)
- Media muestral: \( \bar{x} = 3.5 \)
- Varianza muestral: \( s^2 = 3.3467 \)

Se observa que la media y la varianza presentan valores muy cercanos, lo cual sugiere la presencia de equidispersi√≥n en los datos. Este resultado es coherente con el supuesto de una distribuci√≥n Poisson y respalda su uso como modelo candidato para describir el n√∫mero de visitas a emergencia por paciente. No obstante, esta evidencia exploratoria debe complementarse con una prueba formal de bondad de ajuste, como la prueba Chi‚Äìcuadrado, que se presenta en la siguiente secci√≥n.


```{r, echo=FALSE, message=FALSE, warning=FALSE}
x <- datos$eventos_poisson
x <- x[!is.na(x)]

tabla_resumen_x <- data.frame(
  n = length(x),
  min = min(x),
  max = max(x),
  media = mean(x),
  varianza = var(x)
)

kable(tabla_resumen_x, format="html", caption="Resumen de eventos_poisson") %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped","hover","condensed"))

ggplot(data.frame(x=x), aes(x=factor(x))) +
  geom_bar() +
  labs(x="N√∫mero de visitas (conteo)", y="Frecuencia",
       title="Distribuci√≥n observada de eventos_poisson")
```

El histograma muestra la distribuci√≥n emp√≠rica del n√∫mero de visitas a emergencia por paciente, una variable de conteo discreta. Se observa que:

La mayor concentraci√≥n de observaciones se encuentra alrededor de los valores 2, 3 y 4 visitas, siendo 3 el valor m√°s frecuente, lo cual es coherente con la media muestral \( \bar{x} = 3.5 \)

La distribuci√≥n presenta asimetr√≠a positiva, con una cola hacia la derecha, caracter√≠stica t√≠pica de una distribuci√≥n Poisson.

La frecuencia disminuye progresivamente a medida que aumenta el n√∫mero de visitas, y los valores grandes (por ejemplo, 7, 8 o 9 visitas) aparecen con baja frecuencia, lo cual es esperado en un modelo Poisson conùúÜmoderado. La masa principal se concentra cerca del valor de la media


---

### **3.1.2 Ajuste a Poisson(Œª) y prueba Chi-cuadrado**

### **Hip√≥tesis**
- **H0:** \(X \sim \text{Poisson}(\lambda)\)  
- **H1:** \(X\) no sigue Poisson(\(\lambda\))

### **Estimaci√≥n del par√°metro**
Para Poisson, el estimador natural es:
\[
\hat{\lambda} = \bar{X}
\]

### **Prueba Chi-cuadrado**
Con el objetivo de evaluar si la variable eventos_poisson puede modelarse mediante una distribuci√≥n Poisson, se aplic√≥ una prueba Chi-cuadrado de bondad de ajuste. Esta prueba compara las frecuencias observadas en los datos con las frecuencias esperadas bajo una distribuci√≥n Poisson con par√°metro ùúÜ,estimado a partir de la media muestral. Para garantizar la validez del contraste, se agruparon las categor√≠as de mayor valor cuando fue necesario, asegurando que las frecuencias esperadas no sean demasiado peque√±as (la regla pr√°ctica dice al menos 5).

En la tabla de frecuencias, \(k\) representa los posibles valores del n√∫mero de visitas (conteos), *obs* corresponde a las frecuencias observadas en la muestra para cada valor de \(k\), mientras que *exp* indica las frecuencias esperadas bajo el modelo Poisson ajustado con \(\hat{\lambda} = 3.5\). La comparaci√≥n entre ambas columnas permite evaluar qu√© tan cercanos son los datos reales al comportamiento te√≥rico esperado. Se observa que las frecuencias observadas y esperadas son bastante similares en la mayor√≠a de las categor√≠as, lo cual respalda el buen ajuste del modelo Poisson.



```{r, echo=FALSE, message=FALSE, warning=FALSE}
lambda_hat <- mean(x)

# Frecuencias observadas
obs_tab <- table(x)
k_vals <- as.integer(names(obs_tab))

# Esperadas bajo Poisson(lambda_hat)
p_exp <- dpois(k_vals, lambda_hat)
exp_freq <- length(x) * p_exp

df_gof <- data.frame(
  k = k_vals,
  obs = as.numeric(obs_tab),
  exp = as.numeric(exp_freq)
)

# Agrupar colas para que exp >= 5
agrupar_colas <- function(df, umbral=5){
  df <- df[order(df$k), ]
  while(nrow(df) > 1 && df$exp[1] < umbral){
    df$k[2] <- paste0(df$k[1], "-", df$k[2])
    df$obs[2] <- df$obs[1] + df$obs[2]
    df$exp[2] <- df$exp[1] + df$exp[2]
    df <- df[-1, ]
  }
  while(nrow(df) > 1 && df$exp[nrow(df)] < umbral){
    n <- nrow(df)
    df$k[n-1] <- paste0(df$k[n-1], "-", df$k[n])
    df$obs[n-1] <- df$obs[n-1] + df$obs[n]
    df$exp[n-1] <- df$exp[n-1] + df$exp[n]
    df <- df[-n, ]
  }
  df
}

df_gof2 <- agrupar_colas(df_gof, umbral=5)

# Estad√≠stico Chi-cuadrado
chi2 <- sum((df_gof2$obs - df_gof2$exp)^2 / df_gof2$exp)

# gl = (#clases) - 1 - (#par√°metros estimados)
gl <- nrow(df_gof2) - 1 - 1  # se estima lambda

p_val <- 1 - pchisq(chi2, df=gl)

kable(df_gof2, format="html",
      caption=paste0("GOF Poisson: Observadas vs Esperadas (ŒªÃÇ=", round(lambda_hat,3), ")")) %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped","hover","condensed"))

kable(data.frame(
  lambda_hat = lambda_hat,
  chi2 = chi2,
  gl = gl,
  p_value = p_val
), format="html", caption="Prueba Chi-cuadrado de bondad de ajuste (Poisson)") %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped","hover","condensed"))
```


### **Interpretaci√≥n**

En este caso el p valor obtenido fue de **0.14** el cual es superior a 0.05, por lo tanto no se rechaza Ho, entonces Poisson es compatible con los datos

---

### **3.1.3 Gr√°fico Observado vs Esperado (Poisson)**


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Usamos el df sin agrupar para ver detalle fino
df_plot <- df_gof %>%
  mutate(k = as.numeric(k))

ggplot(df_plot, aes(x=k)) +
  geom_col(aes(y=obs), alpha=0.8) +
  geom_point(aes(y=exp), size=2) +
  geom_line(aes(y=exp), linewidth=0.8) +
  labs(x="k", y="Frecuencia",
       title=paste0("Observado (barras) vs Esperado (l√≠nea) Poisson, ŒªÃÇ=", round(lambda_hat,3)))
```

En el gr√°fico Observado vs Esperado se comparan las frecuencias observadas (barras) del n√∫mero de visitas con las frecuencias esperadas bajo una distribuci√≥n Poisson con par√°metro estimado \(\hat{\lambda} = 3.5\) (l√≠nea). 

Se aprecia que, para la mayor√≠a de los valores de \(k\), las barras se encuentran cercanas a la curva te√≥rica, lo que indica una buena relaci√≥n entre los datos emp√≠ricos y el modelo Poisson ajustado. Las mayores discrepancias se presentan √∫nicamente en los extremos, donde las frecuencias son bajas, lo cual es esperable en distribuciones de conteo. El gr√°fico respalda visualmente el resultado de la prueba Chi-cuadrado, sugiriendo que el modelo Poisson es adecuado para describir el comportamiento del n√∫mero de visitas a emergencia.


---

### **3.1.4 Bondad de ajuste para tiempo_recuperacion (continua positiva)**

### **3.1.5 Exploraci√≥n y candidatos**

Dado que la variable *tiempo_recuperacion* mide el n√∫mero de d√≠as transcurridos hasta la recuperaci√≥n de un paciente, se trata de una variable continua y estrictamente positiva. Este tipo de variables suele presentar asimetr√≠a a la derecha, ya que la mayor√≠a de los pacientes se recupera en un tiempo relativamente corto, mientras que un grupo reducido puede requerir periodos mucho m√°s prolongados. 

Por eso, se consideran distribuciones continuas definidas en el soporte positivo, como la Exponencial, que asume un riesgo constante en el tiempo; la Gamma y la Weibull, que permiten mayor flexibilidad en la forma de la distribuci√≥n; y tambi√©n la Lognormal, que es adecuada para variables con fuerte asimetr√≠a y colas largas hacia la derecha.

Por otro lado, el tiempo de recuperaci√≥n presenta un valor m√≠nimo de 0.15 d√≠as y un valor m√°ximo de 357.36 d√≠as, lo que evidencia una alta variabilidad entre pacientes. La media muestral es de 47.72 d√≠as, mientras que la mediana es de 35.02 d√≠as, lo cual indica una clara asimetr√≠a positiva, ya que la media es mayor que la mediana. Esta diferencia sugiere la presencia de valores extremos elevados que alargan la cola derecha de la distribuci√≥n. 

Adem√°s, la desviaci√≥n est√°ndar cercana a la media refuerza la idea de una distribuci√≥n dispersa y no sim√©trica, lo que respalda la necesidad de evaluar modelos distintos a la Normal para describir adecuadamente el tiempo de recuperaci√≥n.


```{r, echo=FALSE, message=FALSE, warning=FALSE}
t <- datos$tiempo_recuperacion
t <- t[!is.na(t) & t > 0]

kable(data.frame(
  n = length(t),
  min = min(t),
  max = max(t),
  media = mean(t),
  sd = sd(t),
  mediana = median(t)
), format="html", caption="Resumen de tiempo_recuperacion") %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped","hover","condensed"))

ggplot(data.frame(t=t), aes(x=t)) +
  geom_histogram(bins=25) +
  labs(x="D√≠as", y="Frecuencia",
       title="Histograma de tiempo_recuperacion")
```

El histograma del *tiempo_recuperacion* muestra una distribuci√≥n  asim√©trica a la derecha. La mayor concentraci√≥n de observaciones se encuentra en tiempos de recuperaci√≥n bajos, mientras que existe una cola larga hacia valores altos, lo que indica la presencia de algunos pacientes con periodos de recuperaci√≥n prolongados. Este patr√≥n es caracter√≠stico de variables continuas positivas y confirma haber elegido distribuciones como la Exponencial, Gamma, Weibull o Lognormal para el an√°lisis de bondad de ajuste.

---

### **3.1.6 Ajuste por m√°xima verosimilitud + comparaci√≥n AIC/BIC**

El m√©todo de m√°xima verosimilitud consiste en estimar los par√°metros del modelo que hacen m√°s probable la muestra observada, bajo el supuesto de una distribuci√≥n espec√≠fica. Este enfoque es ampliamente utilizado en inferencia estad√≠stica debido a sus buenas propiedades asint√≥ticas, como consistencia y eficiencia, y porque permite comparar distintos modelos ajustados a los mismos datos de manera objetiva.

En este estudio, las distribuciones candidatas para la variable *tiempo_recuperacion* fueron ajustadas mediante m√°xima verosimilitud y luego  comparadas utilizando los criterios de informaci√≥n AIC y BIC. Ambos criterios penalizan la complejidad de la distribuci√≥n ajustada, favoreciendo aquella que logra un mejor equilibrio entre calidad de ajuste y parsimonia. La distribuci√≥n con el menor valor de AIC se considera la m√°s adecuada entre las comparadas; si AIC y BIC coinciden en se√±alar la misma distribuci√≥n, la elecci√≥n resulta se justifica m√°s.


```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(fitdistrplus)

fit_exp  <- fitdist(t, "exp")
fit_gam  <- fitdist(t, "gamma")
fit_wei  <- fitdist(t, "weibull")
fit_lnor <- fitdist(t, "lnorm")

gof <- gofstat(
  list(fit_exp, fit_gam, fit_wei, fit_lnor),
  fitnames = c("Exponencial","Gamma","Weibull","Lognormal")
)

tabla_comp <- data.frame(
  Modelo = names(gof$aic),
  AIC = as.numeric(gof$aic),
  BIC = as.numeric(gof$bic)
) %>% arrange(AIC)

kable(tabla_comp, format="html",
      caption="Comparaci√≥n de ajuste para tiempo_recuperacion (AIC/BIC)") %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped","hover","condensed"))
```

A partir de la tabla de comparaci√≥n, se observa que el modelo Exponencial presenta los valores m√°s bajos tanto de AIC como de BIC, lo que sugiere que es el modelo que mejor describe el comportamiento del tiempo de recuperaci√≥n entre los considerados. Los modelos Gamma y Weibull muestran valores cercanos, mientras que el modelo Lognormal presenta un ajuste claramente inferior seg√∫n ambos criterios.


---

### **3.1.7 Gr√°ficos diagn√≥sticos (densidad, QQ, PP, CDF)**

La **densidad emp√≠rica vs te√≥rica** muestra que el modelo reproduce adecuadamente la asimetr√≠a positiva y la forma general de los datos.  
El **gr√°fico Q‚ÄìQ** nos dice que hay un buen ajuste en los cuantiles centrales, con ligeras desviaciones en la cola derecha asociadas a valores extremos.  
La **CDF emp√≠rica vs te√≥rica** evidencia una concordancia global en la acumulaci√≥n de probabilidades a lo largo del rango de datos.  
El **gr√°fico P‚ÄìP** tiene alineaci√≥n cercana a la diagonal, lo que respalda un ajuste razonable del modelo en t√©rminos de probabilidades.

Estos gr√°ficos diagn√≥sticos complementan la prueba formal de bondad de ajuste, ya que permiten evaluar visualmente qu√© tan bien la distribuci√≥n seleccionada reproduce la forma, los cuantiles y las probabilidades observadas en los datos. La concordancia observada en la densidad, la CDF y los gr√°ficos Q‚ÄìQ y P‚ÄìP es coherente con los resultados obtenidos mediante los criterios AIC/BIC, reforzando la evidencia de un ajuste adecuado de la distribuci√≥n elegida.


```{r, echo=FALSE, message=FALSE, warning=FALSE}
par(mfrow = c(2,2))
plot(fit_lnor)
par(mfrow = c(1,1))
```



## **3.2 Estimadores y propiedades**

Dado que la variable **eventos_poisson** corresponde a un conteo de visitas a emergencia y, seg√∫n la prueba de bondad de ajuste, es compatible con una distribuci√≥n Poisson, se asume que
\[
X_1,\dots,X_n \overset{iid}{\sim}\text{Poisson}(\lambda),
\]
donde \(\lambda>0\) representa el n√∫mero promedio de visitas a emergencia por paciente. A continuaci√≥n, se proponen al menos cinco estimadores puntuales de \(\lambda\) y se verifican propiedades como insesgamiento (o sesgo), consistencia y eficiencia (cuando aplica).



---

## **3.2.1 Estimadores de \(\lambda\)**

En el caso de la distribuci√≥n Poisson, varios procedimientos cl√°sicos de estimaci√≥n conducen al mismo estimador puntual del par√°metro \(\lambda\). En particular, el estimador por m√°xima verosimilitud, el estimador por el m√©todo de momentos y la media muestral coinciden num√©ricamente en \(\bar{X}\).

Sin embargo, dado que el objetivo del estudio es analizar y comparar propiedades estad√≠sticas de distintos estimadores, se incorporan adem√°s estimadores alternativos conceptualmente diferentes, construidos a partir de la varianza muestral, la proporci√≥n de ceros y una aproximaci√≥n basada en la mediana.


1) **Media muestral**  
\[
\hat\lambda_1=\bar X
\]

2) **Estimador por m√°xima verosimilitud (MV)**  
Para Poisson, el MV coincide con la media:
\[
\hat\lambda_2=\bar X
\]

3) **M√©todo de momentos (MM)**  
Igualando \(E(X)=\lambda\) con \(\bar X\):
\[
\hat\lambda_3=\bar X
\]

4) **Estimador por varianza (usando \(Var(X)=\lambda\))**  
\[
\hat\lambda_4=S^2
\]
donde \(S^2\) es la varianza muestral.

5) **Estimador basado en la proporci√≥n de ceros**  
En Poisson:
\[
P(X=0)=e^{-\lambda}
\Rightarrow \lambda=-\ln(P(X=0))
\]
Estimador:
\[
\hat\lambda_5=-\ln(\hat p_0),\quad \hat p_0=\frac{\#\{X_i=0\}}{n}
\]

6) **Estimador basado en la mediana** (aprox.)  
La mediana de Poisson cumple aproximadamente \( \text{Med}(X)\approx \lambda - 1/3\).  
Entonces:
\[
\hat\lambda_6=\text{Med}(X)+\frac{1}{3}
\]


---

**C√°lculo en nuestra muestra**


```{r, echo=FALSE, message=FALSE, warning=FALSE}
lambda_1 <- mean(x)                   # media
lambda_4 <- var(x)                    # varianza muestral
p0_hat   <- mean(x == 0)              # proporci√≥n de ceros
lambda_5 <- -log(p0_hat)              # por ceros (si p0_hat > 0)
lambda_6 <- median(x) + 1/3           # aprox por mediana

res_est <- data.frame(
  Estimador = c("ŒªÃÇ1 = media (XÃÑ)",
                "ŒªÃÇ2 = MV (coincide con XÃÑ)",
                "ŒªÃÇ3 = momentos (coincide con XÃÑ)",
                "ŒªÃÇ4 = varianza (S¬≤)",
                "ŒªÃÇ5 = por ceros  -ln(p0hat)",
                "ŒªÃÇ6 = mediana + 1/3 (aprox)"),
  Valor = c(lambda_1, lambda_1, lambda_1, lambda_4, lambda_5, lambda_6)
)

kable(res_est, format="html", caption="Estimadores de Œª calculados con la muestra") %>%
  kable_styling(full_width = FALSE,
                bootstrap_options = c("striped","hover","condensed"))
```

En la Tabla se presentan los valores de los distintos estimadores puntuales del par√°metro \(\lambda\) calculados a partir de la muestra observada. Se observa que la media muestral, el estimador de m√°xima verosimilitud y el estimador por m√©todo de momentos coinciden exactamente, lo cual es consistente con la teor√≠a de la distribuci√≥n Poisson, donde estos tres enfoques conducen al mismo estimador. 

El estimador basado en la varianza muestral toma un valor ligeramente menor, lo que refleja la variabilidad propia de \(S^2\) en muestras finitas. Por su parte, el estimador basado en la proporci√≥n de ceros produce un valor algo mayor, debido a la sensibilidad del logaritmo frente a peque√±as variaciones en la frecuencia de ceros observados. Finalmente, el estimador basado en la mediana constituye una aproximaci√≥n robusta, cuyo valor cercano a los anteriores sugiere que no existen asimetr√≠as extremas ni valores at√≠picos severos en la muestra. 

En resumen, la cercan√≠a entre los distintos estimadores muestran la estabilidad de la estimaci√≥n de \(\lambda\) y la adecuaci√≥n del supuesto Poisson para los datos analizados.

---

## **3.2.1 Verificaci√≥n de propiedades**

### **3.2.1.1 Insesgadez**

Para verificar emp√≠ricamente las propiedades de los estimadores propuestos, se realiz√≥ un estudio de simulaci√≥n Monte Carlo bajo el supuesto \(X_1,\dots,X_n \sim \text{Poisson}(\lambda_0)\), con \(\lambda_0 = 3.5\), tama√±o muestral \(n = 200\) y \(B = 20000\) r√©plicas. En cada simulaci√≥n se gener√≥ una muestra Poisson y se calcularon los distintos estimadores de \(\lambda\). A partir de estas r√©plicas se estimaron el sesgo, la varianza y el error cuadr√°tico medio (ECM) de cada estimador.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123)

# =========================
# Par√°metros de simulaci√≥n
# =========================
x_real <- datos$eventos_poisson   # datos reales
n <- length(x_real)               # tama√±o muestral
lambda0 <- mean(x_real)           # valor de referencia (Œª‚ÇÄ)
B <- 20000                        # n√∫mero de simulaciones Monte Carlo

# =========================
# Funci√≥n que calcula estimadores
# =========================
calc_estimadores <- function(xs){

  p0 <- mean(xs == 0)

  c(
    lam1 = mean(xs),                    # ŒªÃÇ‚ÇÅ = media muestral
    lam4 = var(xs),                     # ŒªÃÇ‚ÇÑ = varianza muestral
    lam5 = ifelse(p0 > 0, -log(p0), NA),# ŒªÃÇ‚ÇÖ = estimador por ceros
    lam6 = median(xs) + 1/3             # ŒªÃÇ‚ÇÜ = mediana + 1/3
  )
}

# =========================
# Simulaci√≥n Monte Carlo
# =========================
sim <- replicate(
  B,
  calc_estimadores(rpois(n = n, lambda = lambda0))
)

sim <- t(sim) |> as.data.frame()

# =========================
# Sesgo, varianza y ECM
# =========================
res_mc <- data.frame(
  Estimador = c("ŒªÃÇ‚ÇÅ = XÃÑ", "ŒªÃÇ‚ÇÑ = S¬≤", "ŒªÃÇ‚ÇÖ = ‚àíln(pÃÇ‚ÇÄ)", "ŒªÃÇ‚ÇÜ = Med + 1/3"),
  Sesgo = colMeans(sim - lambda0, na.rm = TRUE),
  Varianza = apply(sim, 2, var, na.rm = TRUE),
  ECM = colMeans((sim - lambda0)^2, na.rm = TRUE)
)

kable(
  res_mc,
  format = "html",
  digits = 4,
  caption = paste0(
    "Verificaci√≥n Monte Carlo del insesgamiento (Œª‚ÇÄ = ",
    round(lambda0, 3),
    ", n = ", n,
    ", B = ", B, ")"
  )
) %>%
  kable_styling(
    full_width = FALSE,
    bootstrap_options = c("striped", "hover", "condensed")
  )
```


Los resultados muestran que la media muestral presenta un sesgo pr√°cticamente nulo y el menor ECM, confirmando emp√≠ricamente que es un estimador **insesgado** y eficiente para \(\lambda\) en el caso Poisson. El estimador basado en la varianza muestral exhibe un sesgo peque√±o, pero una varianza considerablemente mayor, lo que incrementa su ECM y lo vuelve menos eficiente. 

El estimador basado en la proporci√≥n de ceros presenta un sesgo positivo apreciable y el mayor ECM, reflejando la sensibilidad de este m√©todo a la variabilidad muestral y a la no linealidad del logaritmo. Finalmente, el estimador basado en la mediana muestra un sesgo leve y una varianza intermedia, comport√°ndose como una alternativa m√°s robusta, aunque menos eficiente que la media muestral.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
set.seed(123)

# Variable original
eventos_poisson <- datos$eventos_poisson
x <- eventos_poisson

# Valor verdadero (referencia)
lambda0 <- mean(x)

# Tama√±os muestrales crecientes
n_vec <- c(20, 50, 100, 200, 500)

# N√∫mero de simulaciones Monte Carlo
B <- 10000
```


---

### **3.2.1.2 Consistencia**



```{r, echo=FALSE, message=FALSE, warning=FALSE}
calc_estimadores <- function(xs){
  
  p0 <- mean(xs == 0)
  
  c(
    lam1 = mean(xs),                 # Media
    lam4 = var(xs),                  # Varianza
    lam5 = ifelse(p0 > 0, -log(p0), NA), # Por ceros
    lam6 = median(xs) + 1/3          # Mediana + 1/3
  )
}
```


---

**Simulaci√≥n Monte Carlo por tama√±o muestral**


```{r, echo=FALSE, message=FALSE, warning=FALSE}
res_consistencia <- lapply(n_vec, function(n){
  
  sim <- replicate(
    B,
    calc_estimadores(rpois(n, lambda0))
  )
  
  sim <- as.data.frame(t(sim))
  
  data.frame(
    n = n,
    Estimador = c("XÃÑ", "S¬≤", "‚àíln(pÃÇ‚ÇÄ)", "Med + 1/3"),
    Sesgo = c(mean(sim$lam1 - lambda0, na.rm = TRUE),
              mean(sim$lam4 - lambda0, na.rm = TRUE),
              mean(sim$lam5 - lambda0, na.rm = TRUE),
              mean(sim$lam6 - lambda0, na.rm = TRUE)),
    Varianza = c(var(sim$lam1, na.rm = TRUE),
                 var(sim$lam4, na.rm = TRUE),
                 var(sim$lam5, na.rm = TRUE),
                 var(sim$lam6, na.rm = TRUE))
  )
})

res_consistencia <- do.call(rbind, res_consistencia)
```


---

**Tabla final**

```{r, echo=FALSE, message=FALSE, warning=FALSE}
knitr::kable(
  res_consistencia,
  digits = 4,
  caption = "Verificaci√≥n Monte Carlo de la consistencia de los estimadores de Œª"
)
```

La consistencia de los estimadores se eval√∫a observando su comportamiento a medida que aumenta el tama√±o muestral. En la Tabla se aprecia que, para todos los estimadores considerados, el sesgo se mantiene cercano a cero o disminuye progresivamente, mientras que la varianza decrece de forma sistem√°tica conforme aumenta \(n\). Este patr√≥n indica que los estimadores convergen al verdadero valor del par√°metro \(\lambda\), lo cual constituye evidencia emp√≠rica de su **consistencia**, en concordancia con los resultados te√≥ricos del modelo Poisson.


### **3.2.1.3 Eficiencia**

En esta secci√≥n se eval√∫a la **eficiencia** de los estimadores propuestos para el par√°metro \(\lambda\) del modelo Poisson, comparando su **varianza emp√≠rica**, obtenida mediante simulaci√≥n Monte Carlo, con la **cota inferior de Cram√©r‚ÄìRao (CRLB)**.

Para una muestra aleatoria \(X_1, \dots, X_n \sim \text{Poisson}(\lambda)\), la cota de Cram√©r‚ÄìRao para cualquier estimador insesgado de \(\lambda\) est√° dada por:

\[
\text{CRLB} = \frac{\lambda}{n}.
\]

Un estimador se considera **eficiente** si su varianza alcanza dicha cota, es decir, si su varianza es igual (o pr√°cticamente igual) a la CRLB

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
library(kableExtra)

# 1. Aseguramos que lambda0 exista (usaremos 3.5 como ejemplo)
lambda0 <- 3.5 
B <- 20000
n_vals <- c(20, 50, 100, 200, 500)

calc_estimadores <- function(xs){
  p0 <- mean(xs == 0)
  c(
    Xbar = mean(xs),
    S2   = var(xs),
    Zeros = ifelse(p0 > 0, -log(p0), NA),
    Med13 = median(xs) + 1/3
  )
}

res_eff <- data.frame()

for(n in n_vals){
  sim <- replicate(B, calc_estimadores(rpois(n, lambda0)))
  sim <- t(sim)
  
  # Calculamos la varianza de cada columna de la simulaci√≥n
  vars_empiricas <- apply(sim, 2, var, na.rm = TRUE)
  
  # CREACI√ìN EXPL√çCITA DEL DATAFRAME
  tmp <- data.frame(
    n = rep(n, 4),
    Estimador = c("Media (Xbar)", "Varianza (S2)", "Ceros (-ln p0)", "Mediana + 1/3"),
    Varianza_empirica = as.numeric(vars_empiricas),
    CRLB = rep(lambda0 / n, 4) # Forzamos a que se repita el valor para cada fila
  )
  
  res_eff <- rbind(res_eff, tmp)
}

# 2. Renderizado de la tabla forzando mostrar todas las columnas
kable(
  res_eff,
  digits = 4,
  format = "html", # Forzamos formato HTML para asegurar visibilidad en RMarkdown
  caption = "Verificaci√≥n de Eficiencia de Cram√©r-Rao"
) %>%
  kable_styling(full_width = F, bootstrap_options = c("striped", "bordered"))
```



A partir de los resultados obtenidos, se observa que el **estimador basado en la media muestral**, \(\bar{X}\), presenta una varianza emp√≠rica pr√°cticamente id√©ntica a la cota de Cram√©r‚ÄìRao para todos los tama√±os muestrales considerados (\(n = 20, 50, 100, 200, 500\)). Este comportamiento confirma emp√≠ricamente que \(\bar{X}\) es un **estimador eficiente de \(\lambda\)** en el modelo Poisson, en concordancia con la teor√≠a estad√≠stica cl√°sica.

En contraste, los estimadores alternativos ‚Äîbasados en la varianza muestral \(S^2\), la proporci√≥n de ceros \(-\ln(\hat{p}_0)\) y la aproximaci√≥n mediante la mediana‚Äî presentan varianzas emp√≠ricas **mayores que la CRLB** para todos los tama√±os muestrales analizados. Si bien estos estimadores pueden ser consistentes, **no son eficientes**, ya que no alcanzan la m√≠nima varianza te√≥rica posible.

En conclusi√≥n, los resultados te√≥ricos y emp√≠ricos muestran que la **media muestral \(\bar{X}\)** es el √∫nico estimador que alcanza la cota de Cram√©r‚ÄìRao y, por tanto, es **eficiente**, mientras que los dem√°s estimadores no.

### **3.2.1.4 Suficiencia y ancilaridad**

En el modelo Poisson, si \(X_1, \dots, X_n \sim \text{Poisson}(\lambda)\), la funci√≥n de verosimilitud depende de los datos √∫nicamente a trav√©s de la suma
\[
T = \sum_{i=1}^n X_i.
\]
Por el **teorema de factorizaci√≥n de Neyman‚ÄìFisher**, esta estad√≠stica es **suficiente** para el par√°metro \(\lambda\). En consecuencia, la media muestral \(\bar{X} = T/n\) tambi√©n es una estad√≠stica suficiente para \(\lambda\).

Respecto a la **ancilaridad**, no existe en el modelo Poisson una estad√≠stica ancilar no trivial √∫til para inferencia sobre \(\lambda\), ya que la distribuci√≥n de las estad√≠sticas relevantes (sumas, medias, varianzas o conteos) depende expl√≠citamente del par√°metro. Por tanto, la ancilaridad **no es importante** en la inferencia para el par√°metro \(\lambda\) en este contexto.

---

## **3.3 Intervalos de confianza**

### **3.3.1 Basado en la Media muestral**

En este caso, se utiliz√≥ el **M√©todo de la Cantidad Pivotal** debido a su exactitud estad√≠stica. A diferencia de las aproximaciones normales, este m√©todo aprovecha la relaci√≥n te√≥rica entre la distribuci√≥n Poisson y la Chi-cuadrado ($\chi^2$). Esto permite obtener l√≠mites de confianza precisos que garantizan la cobertura exacta del par√°metro $\lambda$, independientemente del tama√±o de la muestra.


```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.2.2 Intervalo de Confianza: M√©todo de la Cantidad Pivotal
# =====================================================

# 1. Extracci√≥n correcta del vector de datos
# Aseg√∫rate de que 'datos' sea el nombre de tu dataframe
x_vec <- datos$eventos_poisson 

# 2. Par√°metros
n <- length(x_vec)        # n = 200
S <- sum(x_vec)           # Suma de eventos (S = 700)
alfa <- 0.05              # Confianza del 95%

# 3. Aplicaci√≥n del M√©todo del Pivote (Distribuci√≥n Chi-cuadrado)
# Basado exactamente en el Script del Profesor Miranda
li <- qchisq(alfa/2, 2 * S) / (2 * n)
ls <- qchisq(1 - alfa/2, 2 * (S + 1)) / (2 * n)

# 4. Presentaci√≥n de resultados en formato Tabla
res_pivotal <- data.frame(
  Metodo = "Pivotal (Chi-cuadrado)",
  L√≠mite_Inferior = li,
  L√≠mite_Superior = ls,
  Longitud = ls - li
)

knitr::kable(
  res_pivotal, 
  digits = 4,
  caption = "Intervalo de Confianza al 95% para Œª (M√©todo Pivotal)"
) %>%
  kableExtra::kable_styling(full_width = F, bootstrap_options = c("striped", "hover"))
```

Con un nivel de confianza del 95% ($\alpha = 0.05$), el verdadero valor del par√°metro $\lambda$ (promedio de eventos cl√≠nicos) se encuentra comprendido entre 3.2458 y 3.7656. Dado que el intervalo es estrecho (longitud $\approx 0.52$), los resultados sugieren que la estimaci√≥n puntual de 3.5 es altamente precisa para describir el comportamiento de la poblaci√≥n bajo estudio.

### **3.3.2 Basado en M√°xima Verosimilitud**

Se utiliz√≥ el **M√©todo Estad√≠stico** aprovechando la propiedad de normalidad asint√≥tica del estimador de m√°xima verosimilitud. Este enfoque permite construir el intervalo a partir del error est√°ndar derivado de la informaci√≥n de Fisher, siendo una herramienta eficiente y cl√°sica para muestras grandes ($n=200$) donde la distribuci√≥n del estimador converge a una Normal.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.2.3 Intervalo de Confianza: M√©todo Estad√≠stico (MV)
# =====================================================

# 1. Par√°metros del Estimador de M√°xima Verosimilitud
lambda_mv <- mean(datos$eventos_poisson) # ŒªÃÇ = 3.5
n <- length(datos$eventos_poisson)       # n = 200
alfa <- 0.05

# 2. C√°lculo del Error Est√°ndar (basado en la Informaci√≥n de Fisher)
# Para Poisson, Var(ŒªÃÇ) = Œª/n
error_estandar <- sqrt(lambda_mv / n)

# 3. Valor cr√≠tico de la Normal Est√°ndar
z <- qnorm(1 - alfa/2)

# 4. L√≠mites del Intervalo
li_est <- lambda_mv - z * error_estandar
ls_est <- lambda_mv + z * error_estandar

# 5. Resultados en Tabla
res_estadistico <- data.frame(
  Metodo = "Estad√≠stico (Asint√≥tico MV)",
  L√≠mite_Inferior = li_est,
  L√≠mite_Superior = ls_est,
  Longitud = ls_est - li_est
)

knitr::kable(
  res_estadistico, 
  digits = 4,
  caption = "Intervalo de Confianza al 95% (M√©todo Estad√≠stico)"
) %>%
  kableExtra::kable_styling(full_width = F, bootstrap_options = c("striped", "bordered"))
```

Con un 95% de confianza, $\lambda$ se sit√∫a entre 3.2407 y 3.7593. Al comparar con el m√©todo pivotal, se observa que los l√≠mites son sumamente similares, lo que valida la precisi√≥n de la aproximaci√≥n normal para este conjunto de datos.


### **3.3.3 Basado en M√©todo de Momentos**

Se aplic√≥ el **M√©todo Aleatorio** por ser una t√©cnica robusta que no depende de supuestos de distribuci√≥n asint√≥tica. Al realizar 10,000 remuestreos con reemplazo de la muestra original de 200 pacientes, se gener√≥ una distribuci√≥n emp√≠rica para el estimador de momentos. Esto permite obtener l√≠mites de confianza basados en los percentiles de la simulaci√≥n, reflejando la variabilidad real de los datos observados.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.2.4 Intervalo de Confianza: M√©todo Aleatorio (Bootstrap)
# =====================================================

# 1. Configuraci√≥n de la simulaci√≥n Bootstrap
set.seed(123) # Para que los resultados sean replicables
B <- 10000    # N√∫mero de remuestreos (cl√°sico en el curso)
n <- length(datos$eventos_poisson)
estimaciones_boot <- numeric(B)

# 2. Proceso de remuestreo (Bootstrap para M√©todo de Momentos)
for(i in 1:B) {
  # Tomamos una muestra con reemplazo de los datos originales
  muestra_aux <- sample(datos$eventos_poisson, size = n, replace = TRUE)
  # Calculamos el estimador de momentos (media) para esa muestra
  estimaciones_boot[i] <- mean(muestra_aux)
}

# 3. C√°lculo de los l√≠mites por el m√©todo de percentiles
alfa <- 0.05
li_boot <- quantile(estimaciones_boot, alfa/2)
ls_boot <- quantile(estimaciones_boot, 1 - alfa/2)

# 4. Resultados en Tabla
res_bootstrap <- data.frame(
  Metodo = "Aleatorio (Bootstrap)",
  L√≠mite_Inferior = as.numeric(li_boot),
  L√≠mite_Superior = as.numeric(ls_boot),
  Longitud = as.numeric(ls_boot - li_boot)
)

knitr::kable(
  res_bootstrap, 
  digits = 4,
  caption = "Intervalo de Confianza al 95% para Œª (M√©todo Bootstrap)"
) %>%
  kableExtra::kable_styling(full_width = F, bootstrap_options = c("striped", "hover"))
```

Con un 95% de confianza, $\lambda$ se encuentra entre 3.2499 y 3.76 (los valores exactos depender√°n de la simulaci√≥n). La similitud de este intervalo con los m√©todos anteriores confirma que el estimador es sumamente estable y que la muestra de 200 individuos es lo suficientemente grande como para que todos los enfoques converjan a resultados casi id√©nticos.

### **3.3.4 Basado en la varianza**

Se utiliz√≥ el **M√©todo Aleatorio** para el estimador $\hat{\lambda}_4 = S^2$ debido a que la varianza muestral presenta una distribuci√≥n de muestreo con mayor dispersi√≥n que la media. Dado que no se dispone de una cantidad pivotal exacta y sencilla para la varianza en una poblaci√≥n Poisson, el remuestreo permite estimar los l√≠mites de confianza de forma emp√≠rica, capturando la asimetr√≠a potencial de la distribuci√≥n de $S^2$ sin forzar un supuesto de normalidad que podr√≠a no cumplirse en muestras finitas.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.2.5 Intervalo de Confianza para S¬≤: M√©todo Aleatorio (Bootstrap)
# =====================================================

# 1. Configuraci√≥n
set.seed(123)
B <- 10000
n <- length(datos$eventos_poisson)
boot_s2 <- numeric(B)

# 2. Remuestreo Bootstrap enfocado en la Varianza
for(i in 1:B) {
  # Generamos una muestra con reemplazo
  muestra_aux <- sample(datos$eventos_poisson, size = n, replace = TRUE)
  # Calculamos el estimador de inter√©s: la varianza muestral
  boot_s2[i] <- var(muestra_aux)
}

# 3. C√°lculo de l√≠mites por percentiles (Alfa = 0.05)
alfa <- 0.05
li_s2 <- quantile(boot_s2, alfa/2)
ls_s2 <- quantile(boot_s2, 1 - alfa/2)

# 4. Resultados en Tabla
res_s2 <- data.frame(
  Metodo = "Bootstrap (Varianza S¬≤)",
  L√≠mite_Inferior = as.numeric(li_s2),
  L√≠mite_Superior = as.numeric(ls_s2),
  Longitud = as.numeric(ls_s2 - li_s2)
)

knitr::kable(
  res_s2, 
  digits = 4,
  caption = "Intervalo de Confianza al 95% para Œª usando S¬≤ (Bootstrap)"
) %>%
  kableExtra::kable_styling(full_width = F, bootstrap_options = c("striped", "hover"))
```

Con un nivel de confianza del 95% ($\alpha = 0.05$), el intervalo para el par√°metro $\lambda$ obtenido mediante el estimador de la varianza muestral ($S^2$) es [2.6700, 4.0300]. Este intervalo presenta una longitud de 1.36, siendo el m√°s amplio de todos los m√©todos aplicados. Esta mayor dispersi√≥n confirma emp√≠ricamente que la varianza es un estimador menos eficiente que la media para el modelo Poisson.

### **3.3.5 Basado en la proporci√≥n de ceros**

Se utiliz√≥ el **M√©todo Aleatorio** para el estimador $\hat{\lambda}_5$ debido a que su construcci√≥n depende de una funci√≥n logar√≠tmica de la proporci√≥n de observaciones nulas. Como es con una estructura anal√≠tica compleja, el remuestreo  permite obtener una distribuci√≥n emp√≠rica de $\hat{p}_0$ y transformarla para hallar los l√≠mites de confianza del par√°metro $\lambda$ de forma directa, sin requerir la derivaci√≥n de f√≥rmulas de error est√°ndar.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.2.6 Intervalo de Confianza para Œª‚ÇÖ (Por Ceros): Bootstrap
# =====================================================

# 1. Configuraci√≥n del remuestreo
set.seed(123)
B <- 10000
n <- length(datos$eventos_poisson)
boot_lam5 <- numeric(B)

# 2. Proceso de remuestreo para el Estimador de Ceros
for(i in 1:B) {
  # Generamos muestra con reemplazo
  muestra_aux <- sample(datos$eventos_poisson, size = n, replace = TRUE)
  # Calculamos la proporci√≥n de ceros en la muestra
  p0_hat <- mean(muestra_aux == 0)
  
  # Calculamos ŒªÃÇ‚ÇÖ = -ln(pÃÇ‚ÇÄ) 
  # Se incluye validaci√≥n por si p0_hat fuera 0
  boot_lam5[i] <- if(p0_hat > 0) -log(p0_hat) else NA
}

# 3. C√°lculo de los l√≠mites del intervalo (Percentiles)
alfa <- 0.05
li_lam5 <- quantile(boot_lam5, alfa/2, na.rm = TRUE)
ls_lam5 <- quantile(boot_lam5, 1 - alfa/2, na.rm = TRUE)

# 4. Presentaci√≥n de resultados
res_ceros <- data.frame(
  Metodo = "Bootstrap (Prop. Ceros)",
  L√≠mite_Inferior = as.numeric(li_lam5),
  L√≠mite_Superior = as.numeric(ls_lam5),
  Longitud = as.numeric(ls_lam5 - li_lam5)
)

knitr::kable(
  res_ceros, 
  digits = 4,
  caption = "Intervalo de Confianza al 95% para Œª usando Prop. de Ceros"
) %>%
  kableExtra::kable_styling(full_width = F, bootstrap_options = c("striped", "hover"))
```

Con un nivel de confianza del 95% ($\alpha = 0.05$), el intervalo para el par√°metro poblacional $\lambda$ basado en la proporci√≥n de ceros es [2.99, 5.29]. Al igual que sucede con la varianza, este intervalo es m√°s amplio que el de la media muestral, lo cual muestra que basar la estimaci√≥n √∫nicamente en los valores nulos conlleva una p√©rdida de eficiencia, pero a√∫n as√≠ los l√≠mites siguen siendo coherentes con la naturaleza de los datos cl√≠nicos analizados.

### **3.3.6 Basado en la mediana**

Se seleccion√≥ el **M√©todo Aleatorio** para el estimador $\hat{\lambda}_6$ debido a la naturaleza discreta de la mediana en una distribuci√≥n Poisson. Como la mediana no es una funci√≥n continua de los par√°metros y su distribuci√≥n de muestreo suele ser asim√©trica y con valores discretos, el remuestreo  permite obtener un intervalo de confianza basado en la distribuci√≥n emp√≠rica de los datos. Este enfoque evita limitaciones de los m√©todos asint√≥ticos que asumen una suavidad en la distribuci√≥n que la mediana no posee en muestras peque√±as o medianas.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.2.7 Intervalo de Confianza para Œª‚ÇÜ (Mediana): Bootstrap
# =====================================================

# 1. Configuraci√≥n del remuestreo
set.seed(123)
B <- 10000
n <- length(datos$eventos_poisson)
boot_median <- numeric(B)

# 2. Proceso de remuestreo para el Estimador de la Mediana
for(i in 1:B) {
  # Generamos muestra con reemplazo
  muestra_aux <- sample(datos$eventos_poisson, size = n, replace = TRUE)
  
  # Calculamos el estimador ŒªÃÇ‚ÇÜ = Mediana + 1/3
  boot_median[i] <- median(muestra_aux) + 1/3
}

# 3. C√°lculo de los l√≠mites del intervalo (Percentiles)
alfa <- 0.05
li_med <- quantile(boot_median, alfa/2)
ls_med <- quantile(boot_median, 1 - alfa/2)

# 4. Resultados en Tabla
res_mediana <- data.frame(
  Metodo = "Bootstrap (Mediana + 1/3)",
  L√≠mite_Inferior = as.numeric(li_med),
  L√≠mite_Superior = as.numeric(ls_med),
  Longitud = as.numeric(ls_med - li_med)
)

knitr::kable(
  res_mediana, 
  digits = 4,
  caption = "Intervalo de Confianza al 95% para Œª usando la Mediana"
) %>%
  kableExtra::kable_styling(full_width = F, bootstrap_options = c("striped", "hover"))
```

Con un nivel de confianza del 95% ($\alpha = 0.05$), el intervalo de $\lambda$ basado en la mediana presenta l√≠mites id√©nticos de [3.3333, 3.3333]. Esto ocurre debido a la naturaleza discreta de los datos de Poisson y la alta estabilidad de la mediana en una muestra de 200 pacientes; al realizar el remuestreo (Bootstrap), el valor central no var√≠a entre diferentes n√∫meros enteros, lo que resulta en un intervalo de longitud cero.

---

## **3.4 Prueba para proporciones pareadas**

Para evaluar la efectividad del programa de seguimiento del Ministerio de Salud, el an√°lisis se centra en la evoluci√≥n cl√≠nica de los pacientes entre el inicio y el final del estudio. En este tipo de pruebas, los pacientes que mantuvieron la misma condici√≥n a lo largo de los seis meses no aportan informaci√≥n sobre la direcci√≥n del cambio, por lo que el estudio se focaliza exclusivamente en los casos donde hubo una transici√≥n de estado.

**Planteamiento del contexto**
**Identificaci√≥n de la muestra ($n$):** Al procesar los datos, se identific√≥ un total de 76 pacientes que cambiaron su condici√≥n (pares discordantes). Este grupo representa el total de individuos que mostraron una reacci√≥n, positiva o negativa, al periodo de seguimiento.

**Definici√≥n de "√âxitos" ($X$):** Dentro de estos 76 pacientes, se observ√≥ que 40 de ellos lograron una mejor√≠a cl√≠nica, pasando de un estado Cr√≠tico a uno Estable. Los 36 restantes hicieron la transici√≥n inversa, pasando de Estable a Cr√≠tico.

**Metodolog√≠a:** Se aplicar√° una Prueba Exacta de Binomial mediante la funci√≥n **binom.test.** El objetivo es contrastar si la cantidad de mejor√≠as observadas (40) difiere significativamente de lo que dictar√≠a el azar. Bajo la hip√≥tesis nula, se asume una probabilidad de √©xito de $0.5$ ($H_0: p = 0.5$), lo que indicar√≠a que el programa no tiene un efecto inclinado hacia la mejor√≠a, sino que los cambios ocurren de forma equilibrada en ambas direcciones.

**Hip√≥tesis del Contraste:**

Para formalizar este an√°lisis, planteamos el siguiente sistema de hip√≥tesis basado en las probabilidades de transici√≥n:

$$\begin{cases} 
H_0: p = 0.5 & \text{(No hay cambio neto en la proporci√≥n)} \\ 
H_1: p \neq 0.5 & \text{(Existe un cambio neto significativo)} 
\end{cases}$$

**Donde:**

$p$ es la probabilidad de que un paciente incremente su bienestar cl√≠nico (transici√≥n de estado Cr√≠tico a Estable) dentro del grupo de los 76 pacientes que mostraron cambios.

**Nivel de significancia:**
$\alpha = 0.05$

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# --- Prueba de hip√≥tesis para proporciones con datos pareados ---

# Definici√≥n de par√°metros seg√∫n los datos extra√≠dos (n=76, X=40)
n <- 76   # Total de pacientes que cambiaron (discordantes)
X <- 40   # Pacientes que mejoraron (Cr√≠tico -> Estable)
p_teorica <- 0.5

# 1. Prueba Exacta usando binom.test
prueba_exacta <- binom.test(x = X, n = n, p = p_teorica, alternative = 'two.sided')
print(prueba_exacta)

# 2. Verificaci√≥n manual del p-valor (estilo Script R)
# Se calcula la probabilidad acumulada en la cola superior y se duplica por ser bilateral
pvalor_manual <- 2 * sum(dbinom(X:n, n, p_teorica))
cat("El p-valor verificado manualmente es:", pvalor_manual)
```

**Interpretaci√≥n de Resultados**

Dado que el p-valor ($0.7308$) es considerablemente mayor al nivel de significancia prefijado de $\alpha = 0.05$, no se rechaza la hip√≥tesis nula ($H_0$).

En t√©rminos del programa de salud, esto indica que no existe evidencia estad√≠stica suficiente para afirmar que el seguimiento de seis meses haya generado un cambio neto significativo en la condici√≥n de los pacientes. La proporci√≥n de pacientes que mejoraron su estado (pasando de cr√≠tico a estable) es estad√≠sticamente similar a la proporci√≥n de aquellos que empeoraron, lo que sugiere que los cambios observados en esta muestra de 200 individuos se deben al azar y no a un efecto dominante de la intervenci√≥n.

---

## **3.5 Pruebas de hip√≥tesis con estimadores**

**Prueba de Hip√≥tesis para el Par√°metro $\lambda$ (Basada en la Media Muestral)**:

Se desea verificar si el promedio de eventos cl√≠nicos en la poblaci√≥n de pacientes atendidos es significativamente diferente a un valor de referencia hist√≥rico de 3.2 eventos por paciente $\lambda_0 = 3.2$. Para ello, se utiliza la media muestral $\bar{X}$ como estad√≠stico de prueba sobre una muestra de $n = 200$ individuos, bajo un nivel de significancia del 5% $\alpha = 0.05$.

**Las hip√≥tesis son**

$H_0$: $\lambda = 3.2$ (El promedio de eventos es igual al est√°ndar hist√≥rico).

$H_1$: $\lambda \neq 3.2$ (El promedio de eventos ha cambiado respecto al est√°ndar).

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.4.1 Prueba de Hip√≥tesis Exacta para la Media (Pivotal)
# =====================================================

# 1. Datos y Par√°metros de la prueba
x <- datos$eventos_poisson
n <- length(x)          # n = 200
S_obs <- sum(x)         # Suma observada de eventos (S = 700)
lambda_0 <- 3.2         # Valor bajo la Hip√≥tesis Nula
alfa <- 0.05

# 2. C√°lculo del P-valor (Basado en la relaci√≥n Poisson-Chi cuadrado)
# Seg√∫n la teor√≠a, bajo H0: 2*n*lambda_0 sigue una Chi-cuadrado
# Para una prueba bilateral, calculamos la probabilidad en las colas:
p_valor <- 2 * min(ppois(S_obs, n * lambda_0), 1 - ppois(S_obs - 1, n * lambda_0))

# 3. Determinaci√≥n de Valores Cr√≠ticos (Regi√≥n de Rechazo)
# Usando la distribuci√≥n Chi-cuadrado para la suma de eventos
vc_inf <- qchisq(alfa/2, 2 * S_obs) / (2 * n)
vc_sup <- qchisq(1 - alfa/2, 2 * (S_obs + 1)) / (2 * n)

# 4. Resultados
res_prueba_exacta <- data.frame(
  Parametro_H0 = lambda_0,
  Media_Obs = mean(x),
  Suma_Eventos = S_obs,
  P_Valor = p_valor,
  Decision = ifelse(p_valor < alfa, "Rechazar H0", "No Rechazar H0")
)

print("Resultado de la Prueba de Hip√≥tesis Exacta (Poisson):")
print(res_prueba_exacta)
```

Con un p-valor de 0.02, se rechaza Ho. El promedio de eventos es significativamente diferente de 3.2

---

**Prueba de Hip√≥tesis para el Par√°metro $\lambda$ (Basada en el Estimador de M√°xima Verosimilitud)**

Se desea verificar si el par√°metro de intensidad $\lambda$ es significativamente diferente de un valor hipot√©tico de 3.3 $\lambda_0 = 3.3$. Para este contraste, se emplear√° el Estimador de M√°xima Verosimilitud mediante la prueba de la Raz√≥n de Verosimilitud Asint√≥tica, la cual utiliza el estad√≠stico $-2\ln(\Lambda)$ que se distribuye aproximadamente como una Chi-cuadrado $\chi^2$ con 1 grado de libertad. La prueba se realizar√° con un nivel de significancia del 5% $\alpha = 0.05$.

**Las hip√≥tesis son**

$H_0$: $\lambda = 3.3$ (La intensidad del proceso Poisson es igual a 3.3).

$H_1$: $\lambda \neq 3.3$ (La intensidad del proceso Poisson ha variado significativamente).

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.4.2 Prueba de Hip√≥tesis para Œª_MV: Raz√≥n de Verosimilitud
# =====================================================

# 1. Datos y par√°metros iniciales
x <- datos$eventos_poisson
n <- length(x)
lambda_hat_mv <- mean(x)   # Estimador de M√°xima Verosimilitud
lambda_0 <- 3.3            # Valor bajo H0
alfa <- 0.05

# 2. Funciones de Log-Verosimilitud (Log-Likelihood)
# Basado en la l√≥gica de 'bin2' del script del profesor: suma(log(probabilidades))
# ln L(lambda) = sum(x_i * log(lambda) - lambda - log(x_i!))

log_lik_mv <- sum(x * log(lambda_hat_mv) - lambda_hat_mv - lfactorial(x))
log_lik_h0 <- sum(x * log(lambda_0) - lambda_0 - lfactorial(x))

# 3. Estad√≠stico de la Raz√≥n de Verosimilitud (Likelihood Ratio Statistic)
# En el script: JiCalc = -2 * (ln_max0 - ln_max)
estadistico_rv <- -2 * (log_lik_h0 - log_lik_mv)

# 4. C√°lculo del p-valor y valores cr√≠ticos
# Grados de libertad = 1 (se estima un solo par√°metro lambda)
gl <- 1
p_valor_rv <- pchisq(estadistico_rv, df = gl, lower.tail = FALSE)
ji_tabular <- qchisq(1 - alfa, df = gl)

# 5. Resultados en formato de tabla (siguiendo el estilo 'kbl' del script)
library(kableExtra)
resultados_mv <- data.frame(
  "Grados_Libertad" = gl,
  "Ji_Calculado" = estadistico_rv,
  "Ji_Tabular" = ji_tabular,
  "p_valor" = p_valor_rv,
  "Decision" = ifelse(p_valor_rv < alfa, "Rechazar H0", "No Rechazar H0")
)

resultados_mv %>% 
  kbl(caption = "Prueba de Raz√≥n de Verosimilitud Asint√≥tica para Œª_MV") %>% 
  kable_styling(latex_options = "striped", full_width = F)
```

Con un p-valor de 0.12, no se rechaza Ho, la intensidad del proceso Poisson es igual a 3.3

---

**Prueba de Hip√≥tesis (Basada en el M√©todo de Momentos)**

Se desea verificar si el par√°metro de intensidad $\lambda$ es significativamente menor a 3.7 eventos por paciente $\lambda_0 = 3.7$, utilizando el Estimador de Momentos (que iguala el primer momento muestral con el poblacional). Para esto, se usar√° una prueba de una sola cola (unilateral izquierda) con un nivel de significancia del 5% $\alpha = 0.05$, asumiendo la normalidad asint√≥tica del estad√≠stico para una muestra de $n = 200$.

Se utiliza la Funci√≥n de Distribuci√≥n Normal Est√°ndar (pnorm) para calcular el p-valor asint√≥tico, bas√°ndose en la diferencia entre el promedio observado y el valor hipot√©tico, dividida por el error est√°ndar del estimador.

$H_0$: $\lambda \geq 3.7$ (La intensidad es al menos de 3.7 eventos).

$H_1$: $\lambda < 3.7$ (La intensidad ha disminuido significativamente por debajo de 3.7).

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.4.3 Prueba de Hip√≥tesis para Œª‚ÇÉ (Momentos): M√©todo Estad√≠stico
# =====================================================

# 1. Datos y par√°metros (H0: lambda >= 3.7 vs H1: lambda < 3.7)
x <- datos$eventos_poisson
n <- length(x)              # n = 200
lambda_mom <- mean(x)       # Estimador de Momentos (Media muestral)
lambda_0 <- 3.7             # Valor de referencia bajo H0
alfa <- 0.05

# 2. C√°lculo del Error Est√°ndar bajo H0
# En Poisson, la varianza es igual a lambda. Usamos lambda_0 para el error est√°ndar.
error_est_h0 <- sqrt(lambda_0 / n)

# 3. C√°lculo del Estad√≠stico de Prueba Z
# L√≥gica: (Estimador - Valor_H0) / Error_Est√°ndar
z_obs <- (lambda_mom - lambda_0) / error_est_h0

# 4. C√°lculo del P-valor (Unilateral Izquierda)
# Usando pnorm como en el script del profesor (secci√≥n Ho: mu=120)
p_valor_mom <- pnorm(z_obs)

# 5. Valor Cr√≠tico (Z alfa)
z_critico <- qnorm(alfa)

# 6. Tabla de Resultados
res_mom <- data.frame(
  Estimador_Mom = lambda_mom,
  Lambda_H0 = lambda_0,
  Estadistico_Z = z_obs,
  Valor_Critico_Z = z_critico,
  P_Valor = p_valor_mom,
  Decision = ifelse(p_valor_mom < alfa, "Rechazar H0", "No Rechazar H0")
)

print("Resultado de la Prueba de Hip√≥tesis (M√©todo de Momentos):")
print(res_mom)
```

Con un nivel de confianza del 95% $\alpha = 0.05$, la prueba de hip√≥tesis da un p-valor de 0.07. Al ser este valor ligeramente superior al umbral de significancia establecido, la decisi√≥n estad√≠stica es no rechazar la hip√≥tesis nula $H_0$. Sin embargo, es importante decir que el resultado se encuentra al l√≠mite de la significancia √≥sea se pudo haber rechazado $Ho$. Esto sugiere que, si bien no hay evidencia contundente para afirmar que la tasa es menor a 3.7, se podr√≠a analizar m√°s los datos ya que el estad√≠stico se sit√∫a muy cerca de la regi√≥n de rechazo

---

**Prueba de Hip√≥tesis (Basada en la Varianza Muestral)**

Se desea contrastar si la intensidad de eventos cl√≠nicos $\lambda$ es significativamente distinta de un valor de referencia de 3.8 $\lambda_0 = 3.8$. Para este an√°lisis, se utilizar√° la Varianza Muestral $S^2$ como estad√≠stico de prueba. Como no existe una distribuci√≥n te√≥rica exacta y sencilla para $S^2$ en el modelo Poisson, se emplear√° el M√©todo Aleatorio mediante Simulaci√≥n de Monte Carlo para ver  si la varianza observada es estad√≠sticamente compatible con el valor hipot√©tico, bajo un nivel de significancia del 5%

Se usar√° la funci√≥n rpois() para generar miles de muestras bajo la hip√≥tesis nula $H_0: \lambda = 3.8$ y calcular la varianza en cada una, construyendo as√≠ una distribuci√≥n emp√≠rica para obtener el p-valor.

$H_0$: $\lambda = 3.8$ (La varianza poblacional es igual a 3.8).

$H_1$: $\lambda \neq 3.8$ (La varianza poblacional difiere de 3.8).

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.4.4 Prueba de Hip√≥tesis para Œª‚ÇÑ (Varianza): M√©todo Aleatorio
# =====================================================

# 1. Par√°metros de la prueba
set.seed(123)
n <- length(datos$eventos_poisson) # n = 200
lambda_0 <- 3.8                    # Valor bajo H0
N <- 10^5                          # N√∫mero de simulaciones (como en el script)
s2_obs <- var(datos$eventos_poisson) # Varianza observada en tus datos

# 2. Simulaci√≥n de Monte Carlo (L√≥gica de contador del profesor)
# El profesor usa contadores para ver cu√°ntas veces se cumple una condici√≥n
contador <- 0

for (i in 1:N) {
  # Generamos una muestra bajo el supuesto de que H0 es verdadera
  muestra_sim <- rpois(n, lambda_0)
  
  # Calculamos la varianza de la muestra simulada
  s2_sim <- var(muestra_sim)
  
  # Si la varianza simulada es m√°s extrema que la observada, incrementamos
  # Prueba bilateral: comparamos en t√©rminos absolutos o extremos
  if (s2_sim >= s2_obs) {
    contador <- contador + 1
  }
}

# 3. C√°lculo del P-valor emp√≠rico
# El profesor calcula proporciones de rechazo dividiendo entre N
p_valor <- contador / N

# 4. Resultados
res_varianza <- data.frame(
  Varianza_Obs = s2_obs,
  Lambda_H0 = lambda_0,
  Simulaciones = N,
  P_Valor = p_valor,
  Decision = ifelse(p_valor < 0.05, "Rechazar H0", "No Rechazar H0")
)

print("Resultado de la Prueba de Hip√≥tesis (Simulaci√≥n para Varianza):")
print(res_varianza)
```

Con un p-valor de 0.87, no se rechaza Ho, por lo tanto, la varianza poblacional es igual a 3.8

---

**Prueba de Hip√≥tesis (Basada en la proporci√≥n de ceros)**

Se desea verificar si la intensidad de eventos cl√≠nicos $\lambda$ es significativamente mayor a 3.4 ($\lambda_0 = 3.4$). Bajo el modelo Poisson, esto equivale a probar si la proporci√≥n de ceros en la poblaci√≥n es menor a $e^{-3.4} \approx 0.03337$. Se utilizar√° el conteo de ceros observado en la muestra de $n = 200$ pacientes para realizar una prueba de una sola proporci√≥n con un nivel de significancia del 5%

$H_0$: $\lambda \leq 3.4$ (o $p_0 \geq 0.03337$)

$H_1$: $\lambda > 3.4$ (o $p_0 < 0.03337$)

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.4.5 Prueba de Hip√≥tesis para Œª‚ÇÖ (Prop. Ceros): M√©todo Proporciones
# =====================================================

# 1. Preparaci√≥n de los datos y par√°metros
# Contamos cu√°ntos ceros hay en la muestra (X = n¬∞ de √©xitos)
n_ceros <- sum(datos$eventos_poisson == 0) 
n_total <- length(datos$eventos_poisson)   # n = 200

# Definimos el valor de lambda bajo H0 y lo convertimos a proporci√≥n (p0)
# p0 = P(X=0) = exp(-lambda)
lambda_0 <- 3.4
p0 <- exp(-lambda_0) # Aproximadamente 0.03337

# 2. Prueba Exacta (Basada en la distribuci√≥n Binomial)
# Siguiendo el ejemplo binom.test(69, 310, p0, alternative = 'less') del script
prueba_exacta <- binom.test(x = n_ceros, 
                            n = n_total, 
                            p = p0, 
                            alternative = "less")

# 3. Prueba Z para Proporciones (Asint√≥tica)
# Siguiendo el ejemplo prop.test(69, 310, p=0.26, alternative = 'less') del script
prueba_z <- prop.test(x = n_ceros, 
                      n = n_total, 
                      p = p0, 
                      alternative = "less", 
                      correct = TRUE)

# 4. Resultados en Tabla (Estilo del profesor)
res_prop_ceros <- data.frame(
  "Metodo" = c("Exacto (Binomial)", "Asintotico (Z)"),
  "Ceros_Obs" = n_ceros,
  "Prop_Esperada_H0" = round(p0, 5),
  "P_Valor" = c(prueba_exacta$p.value, prueba_z$p.value),
  "Decision" = c(ifelse(prueba_exacta$p.value < 0.05, "Rechazar H0", "No Rechazar H0"),
                 ifelse(prueba_z$p.value < 0.05, "Rechazar H0", "No Rechazar H0"))
)

print("Resultados de la Prueba de Hip√≥tesis para la Proporci√≥n de Ceros:")
print(res_prop_ceros)
```

Al evaluar el par√°metro $\lambda$ a trav√©s de la presencia de ceros en la muestra, se obtuvieron dos $p$-valores (0.340 para la prueba exacta y 0.321 para la prueba asint√≥tica).

**Hay dos p_valores por estas razones:**

El primero es del **enfoque exacto**, este valor $p = 0.340$ es el m√°s preciso matem√°ticamente. Se basa en la distribuci√≥n Binomial, la cual es discreta y calcula la probabilidad exacta de observar esa cantidad de ceros (o menos) bajo el supuesto de que $H_0$ es cierta.

El segundo es del **enfoque asint√≥tico**, este valor $p = 0.321$ utiliza una aproximaci√≥n a la Normal (Prueba Z). Como la Normal es una distribuci√≥n continua y la Binomial es de "saltos" (discreta), se aplica una "correcci√≥n por continuidad" que suele afectar un poco el $p$-valor.

---

**Prueba de Hip√≥tesis (Basada en la mediana)**

Se desea verificar si el par√°metro de intensidad $\lambda$ es significativamente diferente de un valor de referencia de 3.5 ($\lambda_0 = 3.5$). Se utilizar√° la Mediana muestral ajustada como estad√≠stico de prueba. La mediana en datos discretos cambia a "saltos" y no sigue una distribuci√≥n normal sencilla, entonces se emplear√° una prueba de signos o una simulaci√≥n de Monte Carlo para determinar la probabilidad de observar dicha mediana bajo la hip√≥tesis nula ($\alpha = 0.05$).

$H_0$: $\lambda = 3.5$ (La mediana poblacional es compatible con una intensidad de 3.5).

$H_1$: $\lambda \neq 3.5$ (La mediana poblacional sugiere una intensidad distinta a 3.5).

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# =====================================================
# 3.4.6 Prueba de Hip√≥tesis para Œª‚ÇÜ (Mediana): Simulaci√≥n
# =====================================================

# 1. Configuraci√≥n de la prueba
set.seed(123)
n <- length(datos$eventos_poisson) # n = 200
lambda_0 <- 3.5                    # Valor propuesto en H0
N <- 10^5                          # N√∫mero de repeticiones (seg√∫n el script)

# Calculamos el estimador observado en nuestros datos reales
est_mediana_obs <- median(datos$eventos_poisson) + 1/3

# 2. Proceso de Simulaci√≥n (L√≥gica de contador del Profesor Miranda)
# El profesor usa contadores para evaluar la proporci√≥n de rechazo
contador_extremos <- 0

for (i in 1:N) {
  # Generamos muestra Poisson bajo H0
  muestra_h0 <- rpois(n, lambda_0)
  
  # Calculamos el estimador para la muestra simulada
  est_sim <- median(muestra_h0) + 1/3
  
  # Contamos cu√°ntas veces el azar genera un valor igual o m√°s extremo que el observado
  # Prueba bilateral: medimos la discrepancia absoluta
  if (abs(est_sim - lambda_0) >= abs(est_mediana_obs - lambda_0)) {
    contador_extremos <- contador_extremos + 1
  }
}

# 3. C√°lculo del P-valor emp√≠rico
# Proporci√≥n seg√∫n la l√≥gica del script: contador / N
p_valor_mediana <- contador_extremos / N

# 4. Resultados en tabla (siguiendo el estilo 'kbl' del profesor)
library(kableExtra)
res_mediana_ph <- data.frame(
  "Estimador_Mediana" = est_mediana_obs,
  "Valor_H0" = lambda_0,
  "P_valor" = p_valor_mediana,
  "Decision" = ifelse(p_valor_mediana < 0.05, "Rechazar H0", "No Rechazar H0")
)

res_mediana_ph %>% 
  kbl(caption = "Prueba de Hip√≥tesis para Œª basada en la Mediana (Simulaci√≥n)") %>% 
  kable_styling(latex_options = "striped", full_width = F)
```

Al realizar la prueba de hip√≥tesis para el par√°metro $\lambda$ utilizando el estimador de la mediana ajustada, se obtuvo un p-valor de 1. Este resultado indica que no existe evidencia estad√≠stica alguna para rechazar la hip√≥tesis nula ($H_0$) bajo este m√©todo.

Un p-valor de 1 sucede cuando el valor observado en tus datos reales es exactamente igual al valor m√°s probable (la moda) de la distribuci√≥n bajo la hip√≥tesis nula. En nuestro caso, la mediana observada es id√©ntica a la mediana que se esperar√≠a obtener por puro azar si $\lambda = 3.5$ fuera cierto.

Tambi√©n, en una muestra grande ($n=200$), la mediana es muy estable. Si el valor hipot√©tico ($\lambda_0=3.5$) genera medianas que son casi siempre iguales a la observada, el contador de la simulaci√≥n llega al m√°ximo, generando un p-valor de 1.

## **3.6 Funci√≥n potencia de prueba**

Dado que la poblaci√≥n de eventos cl√≠nicos sigue una distribuci√≥n Poisson, la cual es de naturaleza discreta y no se ajusta a los supuestos de normalidad ni binomialidad, se proceder√° a analizar la sensibilidad de la regla de decisi√≥n mediante el estudio de su Funci√≥n Potencia ($1 - \beta$)

El objetivo es evaluar la capacidad de la prueba para reconocer correctamente la falsedad de la hip√≥tesis nula ($H_0: \lambda = 3.5$) frente a un rango de valores alternativos del par√°metro $\lambda$. Se comparar√° gr√°ficamente el desempe√±o del poder de la prueba bajo dos escenarios de tama√±o de muestra ($n = 200$ frente a un escenario reducido de $n = 50$), utilizando la propiedad de aditividad de la distribuci√≥n Poisson para determinar las regiones cr√≠ticas exactas. En este caso, haremos una representaci√≥n visual con las funciones ggplot2 y theme_dark.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# -------------------------------------------------------------------------
# AN√ÅLISIS DE LA FUNCI√ìN POTENCIA - POBLACI√ìN POISSON (PUNTO E)
# Basado en la metodolog√≠a del Profesor Miranda (Ejemplos 17 y 22)
# -------------------------------------------------------------------------

library(tidyverse)
library(ggthemes) # Para temas avanzados si se desea, aunque usaremos theme_dark

# 1. Par√°metros Iniciales
alpha <- 0.05
lambda0 <- 3.5   # Valor bajo la Hip√≥tesis Nula
n_actual <- 200  # Tu tama√±o de muestra
n_comparar <- 50 # Escenario alternativo para an√°lisis de sensibilidad

# 2. Determinaci√≥n de Valores Cr√≠ticos (k)
# Como la suma de variables Poisson es Poisson: S ~ Pois(n * lambda)
# Buscamos k tal que P(S >= k | lambda0) <= alpha
k_200 <- qpois(1 - alpha, n_actual * lambda0) + 1
k_50  <- qpois(1 - alpha, n_comparar * lambda0) + 1

# 3. Definici√≥n del Rango del Par√°metro Lambda para la curva
lambdas <- seq(2.5, 5.5, 0.01)

# 4. C√°lculo de las Funciones Potencia
# Poder = P(Rechazar H0 | Lambda es Verdadero)
poder_n200 <- ppois(k_200 - 1, n_actual * lambdas, lower.tail = FALSE)
poder_n50  <- ppois(k_50 - 1, n_comparar * lambdas, lower.tail = FALSE)

# 5. Creaci√≥n del Tibble para Graficar
df_potencia <- tibble(
  lambda = lambdas,
  Poder_Actual = poder_n200,
  Poder_Reducido = poder_n50
)

# 6. Visualizaci√≥n Comparativa (Estilo Profesor Miranda - Ejemplo 17-e)
ggplot(data = df_potencia, mapping = aes(x = lambda)) +
  # Curva de Potencia para n = 200
  geom_line(aes(y = Poder_Actual, color = 'n = 200 (Actual)'), linewidth = 1.3) +
  # Curva de Potencia para n = 50
  geom_line(aes(y = Poder_Reducido, color = 'n = 50 (Reducido)'), 
            lty = 2, linewidth = 1.3) +
  # L√≠neas de referencia (Estilo Ejemplo 17-b)
  geom_vline(xintercept = lambda0, color = '#66CDAA', lty = 3, lwd = 1) +
  geom_hline(yintercept = alpha, color = '#66CDAA', lty = 3, lwd = 1) +
  # Etiquetas y T√≠tulos
  labs(
    x = expression(lambda),
    y = 'Poder de la Prueba (1 - Beta)',
    title = 'Comparaci√≥n de Funciones Potencia: Poblaci√≥n Poisson',
    subtitle = paste('Efecto del tama√±o de muestra en la detecci√≥n de cambios (Alpha =', alpha, ')'),
    caption = 'An√°lisis basado en la propiedad de aditividad de la distribuci√≥n Poisson'
  ) +
  # Colores espec√≠ficos y Tema Dark (Referencia Ejemplo 17-e)
  scale_color_manual(
    name = 'Tama√±o de Muestra',
    values = c('n = 200 (Actual)' = '#CDAA7D', 'n = 50 (Reducido)' = 'tomato')
  ) +
  theme_dark() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    legend.position = "bottom"
  )

# 7. C√°lculo de un valor espec√≠fico de potencia (Referencia Ejemplo 17-b)
# ¬øCu√°l es el poder si la verdadera tasa fuera 4.0?
lambda_test <- 4.0
poder_especifico <- ppois(k_200 - 1, n_actual * lambda_test, lower.tail = FALSE)
cat("La probabilidad de detectar correctamente un cambio a lambda =", lambda_test, 
    "con n=200 es:", round(poder_especifico, 4))
```

**Interpretaci√≥n**

La funci√≥n potencia $\pi(\lambda)$ permite evaluar la sensibilidad de la prueba para la poblaci√≥n Poisson, evidenciando su capacidad para rechazar correctamente una hip√≥tesis nula falsa. La curva de color piel, que representa la muestra de $n = 200$, refleja una pendiente mucho m√°s pronunciada y alcanza el nivel de potencia m√°ximo (1.0) de forma m√°s acelerada que la curva roja ($n = 50$). Esto indica una eficacia superior: al tener m√°s datos, la prueba se vuelve m√°s precisa para distinguir entre la realidad y el supuesto inicial, lo que hace que la probabilidad de cometer un Error Tipo II ($\beta$) disminuya dr√°sticamente. 

Por otro lado, con la l√≠nea roja ($n=50$) todav√≠a existe un riesgo alto de "no darse cuenta" del cambio, la l√≠nea color piel sube casi verticalmente hacia el 1, confirmando la consistencia de la prueba. Las l√≠neas celestes validan que bajo $H_0$ ($\lambda = 3.5$), el poder es el nivel de significancia $\alpha = 0.05$; sin embargo, la superioridad de la muestra grande es evidente, ya que ante un cambio a $\lambda = 4.0$, la prueba de $n=200$ garantiza un 97.61% de √©xito en la detecci√≥n, asegurando que pr√°cticamente cualquier incremento importante en la tasa de eventos ser√° bien identificado.

## **3.7 Distribuci√≥n asint√≥tica de la raz√≥n de verosimilitud**

Considerando que la poblaci√≥n en estudio sigue una distribuci√≥n Poisson, se proceder√° a realizar una prueba de hip√≥tesis para el par√°metro $\lambda$ mediante el M√©todo de la Raz√≥n de Verosimilitud. Dado que se cumplen las condiciones de regularidad (soporte independiente del par√°metro e identificabilidad), se aplicar√° el **Teorema de Wilks**, el cual establece que el estad√≠stico de prueba $-2\ln(\Lambda)$ converge asint√≥ticamente a una distribuci√≥n Chi-cuadrado ($\chi^2$) con un grado de libertad.

El an√°lisis va a comparar la verosimilitud del modelo bajo la hip√≥tesis nula ($H_0: \lambda = 3.5$) frente a la verosimilitud del modelo bajo el espacio total de par√°metros, usando el Estimador de M√°xima Verosimilitud (EMV) obtenido de la muestra de $n=200$ observaciones. El c√°lculo se realizar√° mediante la diferencia de las log-verosimilitudes para que haya m√°s precisi√≥n.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# -------------------------------------------------------------------------
# f. PRUEBA LRT (VERSI√ìN DIRECTA SIN ERRORES)
# -------------------------------------------------------------------------

library(kableExtra)
library(tidyverse)

# 1. Preparaci√≥n de valores (Basado en la l√≥gica de bin2)
x_lrt <- datos$eventos_poisson  # Usamos tus datos
n_lrt <- length(x_lrt)
suma_x_lrt <- sum(x_lrt)
lambda0_lrt <- 3.4          # Valor bajo H0
lambda_hat_lrt <- mean(x_lrt)  # EMV bajo Omega

# 2. C√°lculo de Log-Verosimilitudes (F√≥rmula exacta Poisson)
# ln L(lambda) = -n*lambda + suma(x)*ln(lambda)
ln_max_omega <- -n_lrt * lambda_hat_lrt + suma_x_lrt * log(lambda_hat_lrt)
ln_max_omega0 <- -n_lrt * lambda0_lrt + suma_x_lrt * log(lambda0_lrt)

# 3. Estad√≠stico de Wilks (Ji-Calculado)
# Seg√∫n el material: JiCalc = -2 * [ln L(omega0) - ln L(omega)]
A_lrt <- ln_max_omega0 - ln_max_omega
ji_calc_lrt <- -2 * (A_lrt)

# 4. Par√°metros de la distribuci√≥n Chi-cuadrado
df_lrt <- 1
ji_tab_lrt <- qchisq(0.95, df_lrt)
p_val_lrt <- 1 - pchisq(ji_calc_lrt, df_lrt)

# 5. Resultado y Tabla Estilo Miranda
decision_lrt <- if(p_val_lrt < 0.05) "Rechazar H0" else "No rechazar H0"

tabla_f <- data.frame(
  "Grados_Libertad" = df_lrt,
  "Ji_Calculado" = round(ji_calc_lrt, 4),
  "Ji_Tabular" = round(ji_tab_lrt, 4),
  "p_valor" = round(p_val_lrt, 4),
  "Decision" = decision_lrt,
  row.names = "Resultados LRT"
)

# 6. Visualizaci√≥n final
tabla_f %>% 
  kbl() %>% 
  kable_styling(latex_options = "striped", full_width = F)
```

Al comparar la hip√≥tesis nula ($\lambda_0 = 3.4$) mediante la raz√≥n de verosimilitud asint√≥tica, se obtuvo un estad√≠stico Ji-Calculado de 0.5826, valor inferior al Ji-Tabular de 3.8415 ($\chi^2_{0.95, 1}$). Con un p-valor de 0.4453, se concluye que no existe evidencia estad√≠stica suficiente para rechazar $H_0$. Esto indica que la diferencia observada entre el estimador m√°ximo veros√≠mil ($\hat{\lambda} = 3.5$) y el valor postulado es m√≠nima y puede deberse al azar muestral. Por lo tanto, bajo el Teorema de Wilks, se asume que el modelo restringido es una representaci√≥n cre√≠ble de la tasa de eventos cl√≠nicos en la poblaci√≥n.

# **4. Referencias**

Miranda Villag√≥mez, F. (2020). Un curso de inferencia estad√≠stica. Universidad Nacional Agraria La Molina. ISBN 978-612-4387-41-8

Casella, G., & Berger, R. L. (2002). Statistical Inference. Duxbury Thompson Learning.





